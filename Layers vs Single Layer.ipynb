{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eBTi31TqpotN",
        "43NeMVChquhG",
        "koDplMKfpIDs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*   Name: Brinda Gupta\n",
        "*   Enrollment Number: 19/11/EC/001\n",
        "*   Branch: CSE\n",
        "*   Email: brindagupta2002@gmail.com"
      ],
      "metadata": {
        "id": "coLhP0F-2iv6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQtZ5xUCmN6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CSV Function"
      ],
      "metadata": {
        "id": "jD7ljdbF2acj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def create_empty_csv(filename, headers):\n",
        "  \"\"\"\n",
        "  Creates an empty CSV file with specified headers.\n",
        "\n",
        "  Args:\n",
        "      filename: The name of the CSV file to create.\n",
        "      headers: A list of strings representing the CSV header row.\n",
        "  \"\"\"\n",
        "  with open(filename, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(headers)\n",
        "\n",
        "# Example usage\n",
        "headers = [\"Fault Percentage of Single Layer\", \"Inference accuracy of Single Layer\", \"Fault Percentage of Triple Layer\", \"Inference accuracy of Triple Layer\"]\n",
        "create_empty_csv(\"/content/drive/MyDrive/MTech/Experiment/Inference.csv\", headers)"
      ],
      "metadata": {
        "id": "CEnr3EnMyCes"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "def format_floats(row, precision=5):\n",
        "    return [f\"{x:.{precision}f}\" if isinstance(x, float) else x for x in row]\n",
        "def write_to_csv(file_path, row, precision=5):\n",
        "    formatted_row = format_floats(row, precision)\n",
        "    with open(file_path, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(formatted_row)"
      ],
      "metadata": {
        "id": "NFFgbf-1qFkX"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "DATj00OSoEZo"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Masked Tensor Function"
      ],
      "metadata": {
        "id": "7DJ-gVabXUj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masked_tensor(size=(784, 784), percentage=10):\n",
        "\n",
        "\n",
        "  # Create a base tensor with all values set to -1\n",
        "  tensor = torch.ones(size) * -1\n",
        "\n",
        "  # Calculate the number of elements to mask (10% for both 0 and 1)\n",
        "  num_elements = tensor.numel()  # Total number of elements in the tensor\n",
        "  num_to_mask_zero = int(0.85 * percentage/100 * num_elements)\n",
        "  num_to_mask_one = int(0.22 * percentage/100 * num_elements)\n",
        "\n",
        "  # Create random masks for 0 and 1 (size matches the tensor)\n",
        "  mask_zero = torch.rand(size).lt(num_to_mask_zero / num_elements).float()\n",
        "  mask_one = torch.rand(size).lt(num_to_mask_one / num_elements).float()\n",
        "\n",
        "  # Apply masks to set elements to 0 or 1\n",
        "  tensor = tensor * (1 - mask_zero - mask_one) + mask_zero * 0 + mask_one * 1\n",
        "\n",
        "  return tensor"
      ],
      "metadata": {
        "id": "MPhjd0_vS9dB"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Weight Altering Function for Single Layer Memristor Crossbar"
      ],
      "metadata": {
        "id": "xhtXAJYRpeQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alter_weights_single_layer(model, tensor1, tensor2):\n",
        "    # Ensure the tensor shapes match the corresponding weights\n",
        "    assert tensor1.shape == (784, 784), \"tensor1 shape must be (784, 784)\"\n",
        "    assert tensor2.shape == (10, 784), \"tensor2 shape must be (10, 784)\"\n",
        "\n",
        "    # Get the current state dictionary of the model\n",
        "    state_dict = model.state_dict()\n",
        "\n",
        "    # Alter weights for the first layer\n",
        "    weights1 = state_dict['layer1.weight'].clone()\n",
        "    mask1_pos = (tensor1 == 1)\n",
        "    mask1_zero = (tensor1 == 0)\n",
        "    weights1[mask1_pos] = 1\n",
        "    weights1[mask1_zero] = 0\n",
        "    state_dict['layer1.weight'] = weights1\n",
        "\n",
        "    # Alter weights for the second layer\n",
        "    weights2 = state_dict['layer2.weight'].clone()\n",
        "    mask2_pos = (tensor2 == 1)\n",
        "    mask2_zero = (tensor2 == 0)\n",
        "    weights2[mask2_pos] = 1\n",
        "    weights2[mask2_zero] = 0\n",
        "    state_dict['layer2.weight'] = weights2\n",
        "\n",
        "    # Load the altered weights back into the model\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "qNr7sZCKpepR"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Weight Altering Function for Triple Layer Memristor Crossbar"
      ],
      "metadata": {
        "id": "eBTi31TqpotN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alter_weights_triple_layers(model, tensorlist):\n",
        "\n",
        "    # Get the current state dictionary of the model\n",
        "    state_dict = model.state_dict()\n",
        "\n",
        "    # Alter weights for the first layer\n",
        "    weights11 = state_dict['layer1.weight'].clone()\n",
        "    mask1_pos = (tensorlist[0] == 1)\n",
        "    mask1_zero = (tensorlist[0] == 0)\n",
        "    weights11[mask1_pos] = 1\n",
        "    weights11[mask1_zero] = 0\n",
        "\n",
        "    weights12 = state_dict['layer1.weight'].clone()\n",
        "    mask1_pos = (tensorlist[2] == 1)\n",
        "    mask1_zero = (tensorlist[2] == 0)\n",
        "    weights12[mask1_pos] = 1\n",
        "    weights12[mask1_zero] = 0\n",
        "\n",
        "    weights13 = state_dict['layer1.weight'].clone()\n",
        "    mask1_pos = (tensorlist[4] == 1)\n",
        "    mask1_zero = (tensorlist[4] == 0)\n",
        "    weights13[mask1_pos] = 1\n",
        "    weights13[mask1_zero] = 0\n",
        "\n",
        "    state_dict['layer1.weight'] = (weights11+weights12+weights13)/3\n",
        "\n",
        "    # Alter weights for the second layer\n",
        "    # Alter weights for the first layer\n",
        "    weights21 = state_dict['layer2.weight'].clone()\n",
        "    mask2_pos = (tensorlist[1] == 1)\n",
        "    mask2_zero = (tensorlist[1] == 0)\n",
        "    weights21[mask2_pos] = 1\n",
        "    weights21[mask2_zero] = 0\n",
        "\n",
        "    weights22 = state_dict['layer2.weight'].clone()\n",
        "    mask2_pos = (tensorlist[3] == 1)\n",
        "    mask2_zero = (tensorlist[3] == 0)\n",
        "    weights22[mask2_pos] = 1\n",
        "    weights22[mask2_zero] = 0\n",
        "\n",
        "    weights23 = state_dict['layer2.weight'].clone()\n",
        "    mask2_pos = (tensorlist[5] == 1)\n",
        "    mask2_zero = (tensorlist[5] == 0)\n",
        "    weights23[mask2_pos] = 1\n",
        "    weights23[mask2_zero] = 0\n",
        "\n",
        "    state_dict['layer2.weight'] = (weights21+weights22+weights23)/3\n",
        "\n",
        "    # Load the altered weights back into the model\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "JNrdcs_IpoL1"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate of percentages"
      ],
      "metadata": {
        "id": "43NeMVChquhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_value_percentages(tensor):\n",
        "  \"\"\"\n",
        "  Calculates the percentage of 0s and 1s in a PyTorch tensor.\n",
        "\n",
        "  Args:\n",
        "      tensor: A PyTorch tensor.\n",
        "\n",
        "  Returns:\n",
        "      A dictionary containing the percentage of 0s and 1s.\n",
        "  \"\"\"\n",
        "  total_elements = torch.numel(tensor)\n",
        "\n",
        "  # Count occurrences of 0 and 1\n",
        "  count_0 = torch.count_nonzero(tensor == 0).item()\n",
        "  count_1 = torch.count_nonzero(tensor == 1).item()\n",
        "\n",
        "  # Calculate percentages\n",
        "  percent_0 = (count_0 / total_elements) * 100\n",
        "  percent_1 = (count_1 / total_elements) * 100\n",
        "\n",
        "  return {\"0\": percent_0, \"1\": percent_1}"
      ],
      "metadata": {
        "id": "Q6rXJxMCqvAm"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "koDplMKfpIDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "class Baseline(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.layer1 = nn.Linear(784, 784)\n",
        "      self.act1 = nn.ReLU()\n",
        "      self.layer2 = nn.Linear(784, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.act1(self.layer1(x))\n",
        "      x = self.layer2(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "StlmhZ6ioVab"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "p7nj3ib-siif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for fault_percentage in range(0, 15, 2):\n",
        "  #Downloading MNIST Test Data\n",
        "  test = torchvision.datasets.MNIST('data', train=False, download=True)\n",
        "  len(test)\n",
        "  X_test = test.data.reshape(-1, 784).float() / 255.0\n",
        "  y_test = test.targets\n",
        "\n",
        "\n",
        "  #Downloading Weights\n",
        "  MODEL_PATH = Path(\"/content/drive/MyDrive/MTech/Experiment\")\n",
        "  MODEL_NAME = \"base_mnist_clamped.pth\"\n",
        "  MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "  # Loading the saved model\n",
        "  model = Baseline()\n",
        "  model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "  #Making Masks for Single-Layer Memristor Crossbar\n",
        "  Layer1_mask = create_masked_tensor(size=(784, 784), percentage=fault_percentage)\n",
        "  Layer2_mask = create_masked_tensor(size=(10, 784), percentage=fault_percentage)\n",
        "\n",
        "  #Altering the Weights for Single Layer Memristor crossbar\n",
        "  model = alter_weights_single_layer(model, Layer1_mask, Layer2_mask)\n",
        "\n",
        "  #Percentage of total faults in Single Layer Memristor crossbar\n",
        "  percentages = calculate_value_percentages(Layer1_mask)\n",
        "  percentage1 = 0\n",
        "  percentage1 += ((percentages['0']+percentages['1'])*7.84*784)\n",
        "  percentages = calculate_value_percentages(Layer2_mask)\n",
        "  percentage1 += ((percentages['0']+percentages['1'])*7.84*10)\n",
        "  percentage1 /= (784*794)\n",
        "  percentage1 *= 100\n",
        "  # print(\"Percentage of faults in single layer:\", percentage1)\n",
        "\n",
        "  #Testing Accuracy of a single layer Memristor crossbar-based Neural Network\n",
        "  loader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), shuffle=True, batch_size=100)\n",
        "  accuracy1 = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for X_batch, y_batch in loader:\n",
        "          y_pred = model(X_batch)\n",
        "          batch_acc = (torch.argmax(y_pred, 1) == y_batch).float().mean()\n",
        "          accuracy1 += batch_acc.item() * X_batch.size(0)\n",
        "  # Calculate overall accuracy\n",
        "  accuracy1 /= len(loader.dataset)\n",
        "  accuracy1 *= 100\n",
        "  # print(\"Model accuracy with\", i, \"percent faults on test set: %.5f%%\" % accuracy1)\n",
        "\n",
        "\n",
        "\n",
        "  #Downloading MNIST Test Data\n",
        "  test = torchvision.datasets.MNIST('data', train=False, download=True)\n",
        "  len(test)\n",
        "  X_test = test.data.reshape(-1, 784).float() / 255.0\n",
        "  y_test = test.targets\n",
        "\n",
        "  #Dowloading Weights again\n",
        "  MODEL_PATH = Path(\"/content/drive/MyDrive/MTech/Experiment\")\n",
        "  MODEL_NAME = \"base_mnist_clamped.pth\"\n",
        "  MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "  # Loading the saved model\n",
        "  model = Baseline()\n",
        "  model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "  #Getting list for the fault-mask of three layers of memristor crossbar\n",
        "  Tensor_list=[]\n",
        "  for j in range(3):\n",
        "      Layer1_mask = create_masked_tensor(size=(784, 784), percentage=fault_percentage)\n",
        "      Layer2_mask = create_masked_tensor(size=(10, 784), percentage=fault_percentage)\n",
        "      Tensor_list.extend([Layer1_mask, Layer2_mask])\n",
        "  model = alter_weights_triple_layers(model, Tensor_list)\n",
        "\n",
        "\n",
        "  #Percentage of total faults in Triple-layer Memristor crossbar\n",
        "  percentage3 = 0\n",
        "  for i in range(3):\n",
        "    percentages = calculate_value_percentages(Tensor_list[i*2+0])\n",
        "    percentage3+=((percentages['0']+percentages['1'])*7.84*784)\n",
        "    percentages = calculate_value_percentages(Tensor_list[i*2+1])\n",
        "    percentage3+=((percentages['0']+percentages['1'])*7.84*10)\n",
        "  percentage3 = percentage3*100/(794*784)/3\n",
        "  # print(\"Percentage of faults in triple layers:\", percentage3)\n",
        "\n",
        "  #Testing Accuracy of a triple layer Memristor crossbar-based Neural Network\n",
        "  loader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), shuffle=True, batch_size=100)\n",
        "  accuracy3 = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for X_batch, y_batch in loader:\n",
        "          y_pred = model(X_batch)\n",
        "          batch_acc = (torch.argmax(y_pred, 1) == y_batch).float().mean()\n",
        "          accuracy3 += batch_acc.item() * X_batch.size(0)\n",
        "  # Calculate overall accuracy\n",
        "  accuracy3 /= len(loader.dataset)\n",
        "  accuracy3 *= 100\n",
        "  # print(\"Model accuracy on test set: %.5f%%\" % accuracy3)\n",
        "  # if fault_percentage % 2 == 0:\n",
        "  write_to_csv(\"/content/drive/MyDrive/MTech/Experiment/Inference.csv\", [percentage1, accuracy1, percentage3, accuracy3])\n"
      ],
      "metadata": {
        "id": "wbcHGaCynemO"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dc4A5DJ_3Ud7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}